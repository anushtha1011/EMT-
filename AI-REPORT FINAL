% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%
\documentclass[runningheads]{llncs}

%
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
%\usepackage[english]{babel}
\usepackage{amsthm}
\usepackage{algorithm}
% Used for displaying a sample figure. If possible, figure files should
\usepackage{algpseudocode}
\usepackage[graphicx]{}
%\usepackage[linesnumbered,ruled,vlined]{algorithm2e}

% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}

\newtheorem*{myProbStatement}{Problem Statement}
\begin{titlepage}
    \begin{center}
        \vspace*{1cm}
           
        \Huge
        \textbf{ELECTRIC MOTOR TEMPERATURE DETECTION}
            
        \vspace{0.5cm}
        \LARGE
        PROJECT REPORT\\ARTIFICIAL INTELLIGENCE
            
        \vspace{1.5cm}
            
        \textbf{Submitted by:
Anushtha-01201032017
Mahima Sharu-01601032017
Sakshi-02001032017}
\\
\begin{figure}
\centering
\begin{subfigure}
\includegraphics{EMT/P6png.png}
\end{subfigure}
\end{figure}
   
            
        
           \textbf{Under the Supervision of\\
Mr. Rishabh Kaushal\\
Assistant Professor\\
Department of Information Technology}          
    \end{center}
\end{titlepage}
\begin{document}

%
\title{ELECTRIC MOTOR TEMPERATURE DETECTION}
%
%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{
\inst{} \
\inst{}
}
\authorrunning{.}
\institute{Indira Gandhi Delhi Technical University for Women, Delhi, India}

%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
Predicting Stator Temperature and Torque to determine the longevity of motor. This is a predictive maintenance model where durability of motor is predicted based on some input factors using various analysis techniques like Linear Regression and how the maintenance and manufacturing of motor can be improved based on what factors affect its functioning the most.


\end{abstract}
%
%
%
\section{INTRODUCTION}
The Permanent Magnet Synchronous Motor (PMSM) is an AC synchronous motor whose field excitation is provided by permanent magnets, and has a sinusoidal Back EMF waveform. With permanent magnets the PMSM can generate torque at zero speed. The main purpose of the data set's recording is to be able to model the stator temperature of a PMSM in real-time.  In addition, precise thermal modelling gets more and more important with the rising relevance of functional safety 
\subsection{PROBLEM STATEMENT}
Due to the intricate structure of an electric traction drive, direct measurement with thermal sensors is not possible for stator temperatures, sensor outage or even just deterioration can't also be administered properly. 
Being able to have strong estimators for the stator temperature helps the automotive industry to manufacture motors with less material and enables control strategies to utilize the motor to its maximumcapability. A precise torque estimate leads to more accurate and adequate control of the motor, reducing power losses and eventually heat build-up.
However, can we build a model that determines the value of motor temperature to a higher accuracy so that adequate measures be taken for the longer durability of the motor?
%
%
%
%




\section{METHODOLGY}
The data set comprises several sensor data collected from a permanent magnet synchronous motor (PMSM) deployed on a test bench. The PMSM represents a German prototype model.All recordings are sampled at 2 Hz. The data set consists of multiple measurement sessions, which can be distinguished from each other by column Profile id.
A measurement session can be between one and six hours long.\\
The motor is excited by hand-designed driving cycles denoting a reference motor speed and a reference torque.
Currents in d/q-coordinates (columns "id" and iq") and voltages in d/q-coordinates (columns "ud" and "uq") are a result of a standard control strategy trying to follow the reference speed and torque.
Motor Speed and Torque are the resulting quantities achieved by that strategy, derived from set currents and voltages.\\



\subsection{DATA DESCRIPTION}
Number of Instances- 998071\\
Number of Attributes- 13\\
Type- Categorical\\
\\Table \ref{tbl:dataset} represents the description of various attributes present in dataset.


\begin{table}
\centering
\begin{tabular}{|l|c|}
\hline
\textbf{Attribute Name} &  \textbf{Value type}\\
\hline AMBIENT & FLOAT \\
\hline COOLANT  & FLOAT\\
\hline u_d & FLOAT\\
\hline u_q & FLOAT\\
\hline MOTOR SPEED & FLOAT\\
\hline TORQUE & FLOAT\\
\hline i_d & FLOAT\\
\hline i_q & FLOAT\\
\hline pm & FLOAT\\
\hline STATOR YOKE & FLOAT\\
\hline STATOR TOOTH & FLOAT\\
\hline STATOR WINDING & FLOAT\\
\hline PROFILE ID & INT \\
\hline
\end{tabular}
\caption{Details of the dataset.}
\label{tbl:dataset}
\end{table}

\subsection{ATTRIBUTE DESCRIPTION}
 This section demonstrates the individual description of various attributes present in the Dataset in the form of Table 2.
\begin{table}
\centering
\begin{tabular}{|l|c|}
\hline
\textbf{Data Attributes} &  \textbf{Brief Explanation}\\
\hline ambient &Ambient temperature as measured by a thermal sensor located closely to the stator. \\
\hline Coolant  & Coolant temperature. The motor is water cooled. Measurement is taken at outflow. \\
\hline 	u_d &Voltage d-component\\
\hline 	u_q & Voltage q-component\\
\hline motor_speed & Motor speed\\
\hline torque  & Torque induced by current\\
\hline 	i_d &  Current d-component\\
\hline i_q  &Current q-component\\
\hline 	pm & Permanent Magnet surface temperature representing the rotor temperature\\
\hline 	Stator_yoke -& Stator yoke temperature measured with a thermal sensor\\
\hline Stator_tooth & Stator tooth temperature measured with a thermal sensor\\
\hline 	Stator_winding & Stator winding temperature measured with a thermal sensor\\
\hline 	profile_id  & Each measurement session has a unique ID\\
\hline
\end{tabular}\\
\caption{Details of Data Attributes.}
\label{tbl:dataset-attributes}
\end{table}
\subsection{DATA PRE-PROCESSING}
\textbf{2.3.1 DATA CLEANING} \\
The data set comprises several sensor data collected from a permanent magnet synchronous motor (PMSM). Each profile is actually an independent experiment that was conducted and the measures were recorded during each experiment.
\\
\\
\textbf{2.3.2 DATA CLEANING}\\
No row contained NULL values or Missing values so, no processing was required here.

\section{DATA EXPLORATION}
 \textbf{3.1 DATA METRICES}
\begin{table}
\centering
\begin{tabular}{|l|c|}
\hline
\textbf{Data Attributes} &  \textbf{Mean}\\
\hline ambient &-0.003905 \\
\hline Coolant  & 0.004723\\
\hline 	u_d &0.004780\\
\hline 	u_q &-0.005690\\
\hline motor_speed & -0.006336\\
\hline torque  & -0.003333\\
\hline 	i_d &  0.006043\\
\hline i_q  &-0.003194\\
\hline 	pm & -0.004396\\
\hline 	Stator_yoke -& 0.000609\\
\hline Stator_tooth &-0.002208\\
\hline 	Stator_winding &-0.003935\\
\hline 	profile_id  & 50.732001\\
\hline
\end{tabular}\\
\caption{Details of Data Attributes.}
\label{tbl:dataset-attributes}
\end{table}

TOTAL NUMBER OF PROFILE IDs =52

\textbf{3.2 VISUALIZATION}
\subsubsection{ 3.2.1 \textit{Identification of Missing Values}}
\\
The figure above shows the heatmap for different attributes in the dataset. Heatmap is created for the identification of any possible missing values in dataset. As seen, there are no missing values in the dataset, had there been any missing values, they would be shown with different colour.
\begin{figure}
\begin{subfigure}
  \includegraphics{EMT/Picture1.png}
  \caption{missing values}
  \end{subfigure}
\end{figure}

\subsubsection{3.2.2 \textit{Correlation of Variables}}
The figure here is a correlation matrix between different variables. It shows how two variables are related to each other. Dark shades represent positive correlation while lighter shades represent negative correlation. The numerical values are the values by which features are related to each other.

\\Observations: 
\begin{enumerate}
\item There is an almost perfect linear relation between the torque and current suggesting  that we can use linear regression model to estimate the torque using current.
\item The temperatures in stator yoke, tooth and winding are highly correlated since they represent the temperature in the stator and they should be pretty similar (there is no isolation in the stator between those three parts).
\item The coolant seems to be highly correlated with the stator yoke. It is understandable because the coolant runs through the stator yoke to cool it down.
\end{enumerate}

\begin{figure}
\begin{subfigure}
  \includegraphics{EMT/P2.png}
  \caption{Correlation between Variables}
  \end{subfigure}
\end{figure}
\\
\subsubsection{3.2.3 \textit{Motor Speed and rotor temperature}}
Here, this figure shows how motor speed affects change in rotor temperature. Rotor temp is the surface temperature of the motor in which changes are observed as shown in the figure relative to changes taking place in speed of motor which will generate heat loss. It shows that motor temp initially remains constant with gradual increase in speed, then rises linearly relative to increase in speed for some time before it  keeps on rising on constant speed, hence causing heating of motor.

\begin{figure}
\begin{subfigure}
  \includegraphics{EMT/P3png.png}
  \caption{Correlation between Variables}
  \end{subfigure}
\end{figure}

\subsubsection{3.2.4 \textit{Measurement of session length}}
The plot above shows that all measurement sessions range from 20 minutes to around 6 hours. The two short session ids "46" and "47" might be not very representative as temperatures inside electric motors need time to vary.

\begin{figure}
\begin{subfigure}
  \includegraphics{EMT/P5.png}
  \caption{session length}
  \end{subfigure}
\end{figure}

\subsubsection{3.2.5 \textit{Relation between torque and current q- component(i_q)}}
\\
\begin{figure}
\begin{subfigure}
\centering
  \includegraphics{EMT/P4.png}
  \caption{session length}
  \end{subfigure}
\end{figure}
The above figure is a pair plot between torque and current component clearly showing the linear relationship between the two variables. This implies that linear regression model can be used to estimate the torque using the measure of the current i_q.
\section{ALGORITHMS}
\subsection{Implementation of linear regression}
\paragragh{}\\
Linear regression is a linear approach to modelling the relationship between a dependent variable and one or more independent variables. The case of one independent variable is called simple linear regression. For more than one independent variable, the process is called multiple linear regression.
Linear regression was the first type of regression analysis to be studied rigorously, and to be used extensively in practical applications.[4] This is because models which depend linearly on their unknown parameters are easier to fit than models which are non-linearly related to their parameters and because the statistical properties of the resulting estimators are easier to determine.
Linear regression models are often fitted using the least squares approach, but they may also be fitted in other ways, such as by minimizing the "lack of fit" in some other norm (as with least absolute deviations regression), or by minimizing a penalized version of the least squares cost function as in ridge regression (L2-norm penalty) and lasso (L1-norm penalty). Conversely, the least squares approach can be used to fit models that are not linear models. Thus, although the terms "least squares" and "linear model" are closely linked, they are not synonymous.
In the Electric Motor Temperature Database, the data set consists of multiple measurement sessions. The motor is excited by hand-designed driving cycles denoting a reference motor speed and a reference torque.
Currents in d/q-coordinates (columns "id" and iq") and voltages in d/q-coordinates (columns "ud" and "uq") are a result of a standard control strategy trying to follow the reference speed and torque.\\
\\
%
%



\begin{figure}
    
\begin{subfigure}[ht]
\includegraphics{EMT/model visualisation.png}
\caption{model visualization}
\end{subfigure}

\begin{subfigure}[h]
\includegraphics{EMT/residual form.png}
\caption{Residual Form}
\end{subfigure}

\begin{subfigure}[h]
\includegraphics{EMT/root mean.png}
\caption{root mean square value}
\end{subfigure}

\end{figure}


\textbf{4.1.1 Description}\\
\\Figure 6 shows the model visualisation, figure 7 shows the residual error and figure 8 shows the root mean square error for different configurations.
\\

\subsection{Implementation of principal Component Regression}
\paragragh{}
Principal Components Regression is a technique for analyzing multiple regression data that suffer from multicollinearity. When multicollinearity occurs, least squares estimates are unbiased, but their variances are large so they may be far from the true value. By adding a degree of bias to the regression estimates, principal components regression reduces the standard errors. It is hoped that the net effect will be to give more reliable estimates.
Bar plot for percentage of explained variance vs principal component-	


\begin{figure}
\begin{subfigure}
\includegraphics{EMT/principal component.png}
\caption{Bar Plot}
\end{subfigure}
\end{figure}



\\
Following the usual notation, suppose our regression equation may be written in matrix form as Y = XB + e where Y is the dependent variable, X represents the independent variables, B is the regression coefficients to be estimated, and e represents the errors or residuals.
\\

\begin{figure}
\begin{subfigure}
\includegraphics{EMT/PCR model.png}
\caption{PCR model}
\end{subfigure}
\end{figure}

\\
10 component is good for the model because RMSE value is the smallest for this component number. That's why there is no need to tune the model.
\\
\textbf{4.2.1 Description}\\
\\Figure 9 shows the Bar Plot and Figure 10 shows the PCR(Principal Component Regression) Model Tuning for the motor speed prediction.
\\

\subsection{Implementation of polynomial Regression}
\paragraph
Polynomial Regression is a form of linear regression in which the relationship between the independent variable x and dependent variable y is modeled as an nth degree polynomial. Polynomial regression fits a nonlinear relationship between the value of x and the corresponding conditional mean of y, denoted E(y |x).
The basic goal of regression analysis is to model the expected value of a dependent variable y in terms of the value of an independent variable x. In simple regression, we used following equation –
					y = a+bx+e
Residue Error:
As residuals are the difference between any data point and the regression line, they are sometimes called “errors.” Error in this context doesn’t mean that there’s something wrong with the analysis; it just means that there is some unexplained difference. In other words, the residual is the error that isn’t explained by the regression line.
Graph for the implementation of Polynomial Regression for residue model:

\begin{figure}
\begin{subfigure}
\includegraphics{EMT/residual error.png}
\caption{Residual error}
\end{subfigure}
\end{figure}

\textbf{4.3.1 Description}\\
\\From the above graphical representations which shows the residual error based on the Polynomial Regression.
\\



\section{Regularisation}
\subsection{Regularisation in linear regression}\\
This is a form of regression, that constraints / regularizes or shrinks the coefficient estimates towards zero. In other words ,this technique discourages learning a more complex or flexible model,so as to avoid the risk of overfitting.\\

\textbf{5.1.1 Bias and Variance in Regression models}\\
Bias- Bias is the simplifying assumptions made by a model to make the target function easier to learn.
Variance- Variance is the amount that the estimate of the target function will change if different training data was used.
There could be 4 for bias/variance in regression model
\\

\begin{figure}
\begin{subfigure}
\includegraphics{EMT/bias.png}
\caption{low bias and high bias}
\end{subfigure}
\end{figure}

\\1.	As variance increases, the spread of our data point increases which result in less accurate prediction.

2.	As Bias increases the error between our predicted value and the observed values increases. 
\\
\\
Overfitting—As we add more and more parameters to our model,its complexity increases, which results in increasing variance and decreasing bias
To overcome overfitting there are two ways-
1.Reduce the model complexity
2.Regularization
In regularization , what we do is normally we keep the same number of features ,but reduce the magnitude of the coefficients. To do this one can use the plot the coefficient graph of all these variables.
\\

\textbf{5.1.2 Ridge Regression for linear regression}
\\Ridge regression is L2 norm. 
Ridge regression adds “squared magnitude” of coefficient as penalty term to the loss function.
Objective = loss+ α * (sum of square of coefficients)
Here. α (alpha) is the perimeter which balances the amount of emphasis given to minimizing loss v/s minimum sum of square of coefficients.
Alpha can take various values. Here we define alpha which is a penalty factor:
When,
1. The objective becomes same as simple linear regression. We’ll get the same coefficients as simple linear regression.
2. The coefficients will be zero. Because of infinite weight on the square of coefficients, anything less than zero will make the objective infinite
3. The magnitude of alpha will decide the weight given to different parts of the objective. The coefficients will be somewhere between 0 and 1 for simple linear regression.
\\


\\The plots for the best fit line, we see thet as the value of alpha increases the model complexity reduces. Higher the alpha , bigger the penalty though higher values of alpha reduces overfitting , significantly high values can cause  underfitting as well.
In lasso, the magnitude of the coefficient are shrunk to a small magnitude but they are never zero. It shrinks the parameters, therefore it is mostly used to prevent multicollinearty. It reduces the model complexity by coefficient shrinkage.
\\


\textbf{5.1.3 lasso Regression}
\\
LASSO full form is least absolute shrinkage selector operator. It is quite similar to ridge expression. LASSO adds “absolute  value of magnitude” of coefficient as penalty term to the loss function. It uses |βj| (modulus)instead of square of β, as its penalty. In statistics this is known as the L1 norm.
Consider their are 2 parameters in a given problem. Then according to above formulation, the ridge regression is expressed by β1² + β2² ≤ s.
Similarly, for lasso, the equation becomes,|β1|+|β2|≤ s. This implies that lasso coefficients have the smallest RSS(loss function) for all points that lie within the diamond given by |β1|+|β2|≤ s. 
\\


The above iSince ridge regression has a circular constraint with no sharp points, this intersection will not generally occur on an axis, and so the ridge regression coeﬃcient estimates will be exclusively non-zero. However, the lasso constraint has corners at each of the axes, and so the ellipse will often intersect the constraint region at an axis. When this occurs, one of the coeﬃcients will equal zero. In higher dimensions(where parameters are much more than 2), many of the coeﬃcient estimates may equal zero simultaneously.

What does Regularization achieve?
A standard least squares model tends to have some variance in it, i.e. this model won’t generalize well for a data set different than its training data. Regularization, significantly reduces the variance of the model, without substantial increase in its bias. So the tuning parameter λ, used in the regularization techniques described above, controls the impact on bias and variance. As the value of λ rises, it reduces the value of coefficients and thus reducing the variance. Till a point, this increase in λ is beneficial as it is only reducing the variance(hence avoiding overfitting), without loosing any important properties in the data. But after certain value, the model starts loosing important properties, giving rise to bias in the model and thus underfitting. Therefore, the value of λ should be carefully selected.





\textbf{5.1.4 Elastic Net Regression}


It combines the power of L1 and L2 regularisation Elastic regression generally works well when we have a big dataset. Consider that we have a bunch of correlated independent variables in a dataset, then elastic net will simply form a group consisting of these correlated variables. Now if any one of the variable of this group is a strong predictor (meaning having a strong relationship with dependent variable), then we will include the entire group in the model building, because omitting other variables (like what we did in lasso) might result in losing some information in terms of interpretation ability, leading to a poor model performance.
The equation looks like these
 
Elastic Net Regression Equation

\\
where α is the mixing parameter between ridge (α = 0) and lasso (α = 1) and λ.
α= a + b
λ= a / (a+b)
here a and b are weights assigned to L1 and L2 term respectively and set in a such a way that they control trade off between L1 and L2
a * (L1 term) + b* (L2 term)
\\

\\Programmatically we use l1_ratio as a parameter of a function, which alone decides the type of regression\\
\\
(lasso, ridge, Elastic Net) Let alpha (or a+b) = 1, and now consider the following cases:\\

\\•	If l1_ratio =1, therefore if we look at the formula of l1_ratio, we can see that l1_ratio can only be equal to 1 if a=1, which implies b=0. Therefore, it will be a lasso penalty.\\

\\•	Similarly if l1_ratio = 0, implies a=0. Then the penalty will be a ridge penalty.
\\

\\•	For l1_ratio between 0 and 1, the penalty is the combination of ridge and lasso.
\\

\section{CONCLUSION}
Through various analysis procedures as shown above, when performed we were able to determine the various factors that directly or indirectly affect the durability of motor and affects its functioning. Procedures such as:\\
Exploratory Data Analysis (EDA) to understand the attributes and relation between them.\\
Algorithms based on Regression model like implementation of Linear and Principal Component Regression etc. is done.\\
Also, Regularization based on above learning algorithms was also done.\\
FUTURE WORK- Other Machine learning algorithms like Neural networks etc. can be taken under analysis to further understand the nature of all the attributes provided in dataset and to improve the functioning and working of this model.
\end{document}






